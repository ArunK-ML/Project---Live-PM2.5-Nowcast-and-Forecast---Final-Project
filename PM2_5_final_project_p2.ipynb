{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzHzT56B/hDGe7vwWuU2J6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArunK-ML/Project---Live-PM2.5-Nowcast-and-Forecast---Final-Project/blob/main/PM2_5_final_project_p2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c298d8df",
        "outputId": "8b8e6e7c-7f6c-42c5-98c6-66c4d7823433"
      },
      "source": [
        "!pip install streamlit>=1.20\n",
        "!pip install pandas>=2.0\n",
        "!pip install numpy>=1.24\n",
        "!pip install requests>=2.28\n",
        "!pip install scikit-learn>=1.2\n",
        "!pip install joblib>=1.3\n",
        "!pip install plotly>=5.15\n",
        "!pip install python-dateutil\n",
        "!pip install pytz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil) (1.17.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (2025.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta, timezone\n",
        "\n",
        "TZ = timezone.utc\n",
        "LAT, LON = 13.0827, 80.2707   # Chennai (change as needed)\n",
        "HOURS_BACK = 72               # how many past hours of PM2.5\n",
        "RADIUS_KM = 30                # OpenAQ search radius\n",
        "\n",
        "def fetch_openaq_pm25(lat: float, lon: float, hours: int = 168, radius_km: int = 30) -> pd.DataFrame:\n",
        "    end = datetime.now(TZ)\n",
        "    start = end - timedelta(hours=hours)\n",
        "    base = \"https://api.openaq.org/v2/measurements\"\n",
        "    params = {\n",
        "        \"coordinates\": f\"{lat},{lon}\",\n",
        "        \"radius\": int(radius_km * 1000),\n",
        "        \"parameter\": \"pm25\",\n",
        "        \"date_from\": start.isoformat(),\n",
        "        \"date_to\": end.isoformat(),\n",
        "        \"limit\": 10000,\n",
        "        \"sort\": \"desc\",\n",
        "        \"order_by\": \"datetime\",\n",
        "        \"page\": 1,\n",
        "    }\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            r = requests.get(base, params=params, timeout=30)\n",
        "            if r.status_code >= 400:\n",
        "                return pd.DataFrame()\n",
        "            js = r.json()\n",
        "            items = js.get(\"results\", [])\n",
        "            if not items:\n",
        "                break\n",
        "            df = pd.DataFrame(items)\n",
        "            if \"date\" not in df:\n",
        "                break\n",
        "            df = df[[\"date\", \"value\"]]\n",
        "            df[\"datetime\"] = pd.to_datetime(df[\"date\"].apply(lambda d: d.get(\"utc\")), utc=True)\n",
        "            df = df.drop(columns=[\"date\"]).sort_values(\"datetime\")\n",
        "            frames.append(df)\n",
        "            meta = js.get(\"meta\", {})\n",
        "            found = meta.get(\"found\")\n",
        "            page = params[\"page\"]\n",
        "            limit = params[\"limit\"]\n",
        "            if found is None or page * limit >= int(found):\n",
        "                break\n",
        "            params[\"page\"] = page + 1\n",
        "    except Exception:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    if not frames:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df = pd.concat(frames, ignore_index=True)\n",
        "    df = df[(df[\"datetime\"] >= start) & (df[\"datetime\"] <= end)]\n",
        "    # hourly median across stations\n",
        "    df_hour = (\n",
        "        df.set_index(\"datetime\")\n",
        "          .groupby(pd.Grouper(freq=\"1H\"))[\"value\"]\n",
        "          .median()\n",
        "          .reset_index()\n",
        "          .rename(columns={\"value\": \"pm25\"})\n",
        "    )\n",
        "    return df_hour\n",
        "\n",
        "\n",
        "def fetch_openmeteo_aq_pm25(lat: float, lon: float, hours: int = 168) -> pd.DataFrame:\n",
        "    end = datetime.now(TZ)\n",
        "    start = end - timedelta(hours=hours)\n",
        "    url = (\n",
        "        \"https://air-quality-api.open-meteo.com/v1/air-quality?\"\n",
        "        f\"latitude={lat}&longitude={lon}&hourly=pm2_5&past_days={(hours//24)+1}&timezone=UTC\"\n",
        "    )\n",
        "    try:\n",
        "        r = requests.get(url, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        h = r.json().get(\"hourly\", {})\n",
        "        if not h:\n",
        "            return pd.DataFrame()\n",
        "        df = pd.DataFrame({\"datetime\": h.get(\"time\", []), \"pm25\": h.get(\"pm2_5\", [])})\n",
        "        df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], utc=True)\n",
        "        return df[(df[\"datetime\"] >= start) & (df[\"datetime\"] <= end)].reset_index(drop=True)\n",
        "    except Exception:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    pm25 = fetch_openaq_pm25(LAT, LON, hours=HOURS_BACK, radius_km=RADIUS_KM)\n",
        "    if pm25.empty:\n",
        "        pm25 = fetch_openmeteo_aq_pm25(LAT, LON, hours=HOURS_BACK)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aI6euVyN1uki"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pm25"
      ],
      "metadata": {
        "id": "0hxyYsI5-N8D",
        "outputId": "af5b8d3c-8caf-4791-fa84-6fe29be7300e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    datetime  pm25\n",
              "0  2025-10-03 06:00:00+00:00  16.4\n",
              "1  2025-10-03 07:00:00+00:00  17.7\n",
              "2  2025-10-03 08:00:00+00:00  19.2\n",
              "3  2025-10-03 09:00:00+00:00  20.7\n",
              "4  2025-10-03 10:00:00+00:00  20.5\n",
              "..                       ...   ...\n",
              "67 2025-10-06 01:00:00+00:00  19.3\n",
              "68 2025-10-06 02:00:00+00:00  19.3\n",
              "69 2025-10-06 03:00:00+00:00  17.2\n",
              "70 2025-10-06 04:00:00+00:00  16.1\n",
              "71 2025-10-06 05:00:00+00:00  15.9\n",
              "\n",
              "[72 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ee73e73-efcc-429f-b676-8bff47754761\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>pm25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-10-03 06:00:00+00:00</td>\n",
              "      <td>16.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-10-03 07:00:00+00:00</td>\n",
              "      <td>17.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-10-03 08:00:00+00:00</td>\n",
              "      <td>19.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-10-03 09:00:00+00:00</td>\n",
              "      <td>20.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-10-03 10:00:00+00:00</td>\n",
              "      <td>20.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>2025-10-06 01:00:00+00:00</td>\n",
              "      <td>19.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>2025-10-06 02:00:00+00:00</td>\n",
              "      <td>19.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>2025-10-06 03:00:00+00:00</td>\n",
              "      <td>17.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>2025-10-06 04:00:00+00:00</td>\n",
              "      <td>16.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>2025-10-06 05:00:00+00:00</td>\n",
              "      <td>15.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ee73e73-efcc-429f-b676-8bff47754761')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ee73e73-efcc-429f-b676-8bff47754761 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ee73e73-efcc-429f-b676-8bff47754761');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3ad1115e-8c59-49d5-be51-881d6eabf7b4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ad1115e-8c59-49d5-be51-881d6eabf7b4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3ad1115e-8c59-49d5-be51-881d6eabf7b4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e45e53a7-ec6e-4f12-855c-85e3b8e63fee\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pm25')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e45e53a7-ec6e-4f12-855c-85e3b8e63fee button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pm25');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pm25",
              "summary": "{\n  \"name\": \"pm25\",\n  \"rows\": 72,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-10-03 06:00:00+00:00\",\n        \"max\": \"2025-10-06 05:00:00+00:00\",\n        \"num_unique_values\": 72,\n        \"samples\": [\n          \"2025-10-03 10:00:00+00:00\",\n          \"2025-10-05 20:00:00+00:00\",\n          \"2025-10-04 00:00:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pm25\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.6575216730365927,\n        \"min\": 10.9,\n        \"max\": 29.2,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          29.2,\n          20.3,\n          26.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# config.py\n",
        "# Small config defaults — change coordinates to your city\n",
        "\n",
        "DEFAULT_LAT = 13.0827   # Chennai example\n",
        "DEFAULT_LON = 80.2707\n",
        "DEFAULT_RADIUS_M = 10000  # OpenAQ radius in meters\n",
        "DEFAULT_DAYS_HISTORY = 14  # how many days of historical data to pull by default\n"
      ],
      "metadata": {
        "id": "BoMkOxRKIKEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_fetch.py\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta, date\n",
        "from dateutil import parser\n",
        "\n",
        "OPENAQ_API = \"https://api.openaq.org/v2/measurements\"\n",
        "OPENMETEO_API = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "def fetch_openaq_pm25(lat, lon, radius_m=10000, days=14, limit_per_page=10000):\n",
        "    \"\"\"\n",
        "    Fetch PM2.5 measurements from OpenAQ (UTC timestamps).\n",
        "    Aggregates to hourly mean.\n",
        "    Returns DataFrame with index = UTC hourly datetime and column 'pm25'.\n",
        "    \"\"\"\n",
        "    date_to = datetime.utcnow().date()\n",
        "    date_from = date_to - timedelta(days=days)\n",
        "    params = {\n",
        "        \"coordinates\": f\"{lat},{lon}\",\n",
        "        \"radius\": radius_m,\n",
        "        \"parameter\": \"pm25\",\n",
        "        \"date_from\": date_from.isoformat(),\n",
        "        \"date_to\": date_to.isoformat(),\n",
        "        \"limit\": limit_per_page,\n",
        "        \"page\": 1,\n",
        "        \"sort\": \"desc\"\n",
        "    }\n",
        "\n",
        "    rows = []\n",
        "    while True:\n",
        "        r = requests.get(OPENAQ_API, params=params, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        j = r.json()\n",
        "        results = j.get(\"results\", [])\n",
        "        if not results:\n",
        "            break\n",
        "        for rec in results:\n",
        "            # date.utc exists like \"2025-10-04T12:00:00+00:00\"\n",
        "            dt = rec.get(\"date\", {}).get(\"utc\")\n",
        "            if not dt:\n",
        "                continue\n",
        "            try:\n",
        "                ts = parser.isoparse(dt)\n",
        "            except Exception:\n",
        "                continue\n",
        "            rows.append({\"timestamp\": ts, \"pm25\": rec.get(\"value\")})\n",
        "        # paging\n",
        "        params[\"page\"] += 1\n",
        "        # avoid infinite loop if server returns huge data; break if less than limit\n",
        "        if len(results) < limit_per_page:\n",
        "            break\n",
        "\n",
        "    if not rows:\n",
        "        return pd.DataFrame(columns=[\"pm25\"]).astype({\"pm25\": \"float64\"})\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
        "    df = df.set_index(\"timestamp\")\n",
        "    # resample to hourly mean\n",
        "    hourly = df.resample(\"H\").mean().sort_index()\n",
        "    return hourly\n",
        "\n",
        "def fetch_open_meteo_weather(lat, lon, start_date: date, end_date: date, timezone=\"UTC\"):\n",
        "    \"\"\"\n",
        "    Pull hourly weather variables from Open-Meteo.\n",
        "    start_date/end_date are date objects (YYYY-MM-DD).\n",
        "    Returns DataFrame indexed by UTC hourly timestamps with columns:\n",
        "      temperature_2m, relativehumidity_2m, windspeed_10m, winddirection_10m, pressure_msl\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        \"latitude\": lat,\n",
        "        \"longitude\": lon,\n",
        "        \"hourly\": \",\".join(\n",
        "            [\"temperature_2m\", \"relativehumidity_2m\", \"windspeed_10m\", \"winddirection_10m\", \"pressure_msl\"]\n",
        "        ),\n",
        "        \"start_date\": start_date.isoformat(),\n",
        "        \"end_date\": end_date.isoformat(),\n",
        "        \"timezone\": timezone  # can pass \"UTC\" or \"auto\"\n",
        "    }\n",
        "    r = requests.get(OPENMETEO_API, params=params, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    j = r.json()\n",
        "    hourly = j.get(\"hourly\", {})\n",
        "    if not hourly:\n",
        "        return pd.DataFrame()\n",
        "    times = [pd.to_datetime(t).tz_convert(None) if pd.to_datetime(t).tzinfo else pd.to_datetime(t) for t in hourly.get(\"time\", [])]\n",
        "    df = pd.DataFrame(hourly)\n",
        "    # drop the time column duplication\n",
        "    df = df.drop(columns=[\"time\"], errors=\"ignore\")\n",
        "    df.index = pd.to_datetime(hourly[\"time\"])\n",
        "    # ensure timezone naive UTC for alignment\n",
        "    df.index = pd.to_datetime(df.index).tz_convert(None)\n",
        "    df = df.sort_index()\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "4yhc_xEwIX6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def add_time_features(df):\n",
        "    df = df.copy()\n",
        "    # ensure datetime index\n",
        "    idx = pd.DatetimeIndex(df.index)\n",
        "    df[\"hour\"] = idx.hour\n",
        "    df[\"weekday\"] = idx.weekday\n",
        "    df[\"month\"] = idx.month\n",
        "    return df\n",
        "\n",
        "def make_lag_roll_features(df, target_col=\"pm25\", max_lag=24):\n",
        "    \"\"\"\n",
        "    df must have 'pm25' in index-aligned rows. Returns DataFrame with lag & rolling features.\n",
        "    \"\"\"\n",
        "    out = df.copy()\n",
        "    # lags\n",
        "    for lag in range(1, max_lag + 1):\n",
        "        out[f\"lag_{lag}\"] = out[target_col].shift(lag)\n",
        "    # rolling windows\n",
        "    out[\"roll_mean_3\"] = out[target_col].rolling(3, min_periods=1).mean().shift(1)\n",
        "    out[\"roll_mean_6\"] = out[target_col].rolling(6, min_periods=1).mean().shift(1)\n",
        "    out[\"roll_mean_24\"] = out[target_col].rolling(24, min_periods=1).mean().shift(1)\n",
        "    out[\"roll_std_24\"] = out[target_col].rolling(24, min_periods=1).std().shift(1).fillna(0.0)\n",
        "    return out\n",
        "\n",
        "def build_feature_matrix(pm_df, weather_df=None, max_lag=24):\n",
        "    \"\"\"\n",
        "    pm_df: DataFrame with index hourly, column 'pm25'\n",
        "    weather_df: DataFrame with hourly weather variables aligned to pm_df index (can be None)\n",
        "    Returns X (features), y (target)\n",
        "    \"\"\"\n",
        "    df = pm_df.copy()\n",
        "    if weather_df is not None and not weather_df.empty:\n",
        "        # join weather features (align by index)\n",
        "        df = df.join(weather_df, how=\"left\")\n",
        "    # create time features\n",
        "    df = add_time_features(df)\n",
        "    # lags/rolling\n",
        "    df = make_lag_roll_features(df, target_col=\"pm25\", max_lag=max_lag)\n",
        "    # anomaly flag might later be added outside\n",
        "    # drop rows where target is NaN (can't train on missing y)\n",
        "    y = df[\"pm25\"].copy()\n",
        "    X = df.drop(columns=[\"pm25\"])\n",
        "    # fill missing numeric features sensibly\n",
        "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
        "    X[numeric_cols] = X[numeric_cols].fillna(method=\"ffill\").fillna(method=\"bfill\").fillna(0.0)\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "oxtbSyCEIeKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modeling.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest, HistGradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import joblib\n",
        "\n",
        "def detect_anomalies(series, contamination=0.02, random_state=42):\n",
        "    \"\"\"\n",
        "    series: pandas Series of pm25 values (indexed by time)\n",
        "    returns df with 'anomaly' column (True if anomaly)\n",
        "    \"\"\"\n",
        "    clean = series.fillna(-999).values.reshape(-1, 1)\n",
        "    iso = IsolationForest(contamination=contamination, random_state=random_state)\n",
        "    mask = iso.fit_predict(clean)  # -1 anomaly, 1 normal\n",
        "    anomaly = pd.Series(mask == -1, index=series.index, name=\"anomaly\")\n",
        "    return anomaly\n",
        "\n",
        "def train_regressor(X_train, y_train, X_val=None, y_val=None, random_state=42):\n",
        "    \"\"\"\n",
        "    Fits a time-aware gradient booster (HistGradientBoostingRegressor with early stop).\n",
        "    Returns model and optionally validation MAE.\n",
        "    \"\"\"\n",
        "    model = HistGradientBoostingRegressor(max_iter=400, early_stopping=True, random_state=random_state)\n",
        "    model.fit(X_train, y_train)\n",
        "    val_mae = None\n",
        "    if X_val is not None and y_val is not None:\n",
        "        preds = model.predict(X_val)\n",
        "        val_mae = mean_absolute_error(y_val, preds)\n",
        "    return model, val_mae\n",
        "\n",
        "def recursive_forecast(model, last_known_pm, feature_builder_fn, future_weather_df=None,\n",
        "                       horizon=24, max_lag=24):\n",
        "    \"\"\"\n",
        "    model: trained regressor accepting the features created by feature_builder_fn\n",
        "    last_known_pm: pandas Series indexed by time (most recent value last) including available history for lags\n",
        "    feature_builder_fn: function that takes (pm_series, weather_row, t_index) -> DataFrame with a single row of features (matching training X columns)\n",
        "    future_weather_df: DataFrame indexed by future timestamps with weather columns (optional)\n",
        "    Returns pandas Series of predictions indexed by future timestamps\n",
        "    \"\"\"\n",
        "    preds = []\n",
        "    idx = []\n",
        "    working_series = last_known_pm.copy().astype(float)\n",
        "\n",
        "    # start forecast at next hour\n",
        "    next_ts = working_series.index[-1] + pd.Timedelta(hours=1)\n",
        "    for h in range(horizon):\n",
        "        # select weather for this hour if provided\n",
        "        weather_row = None\n",
        "        if future_weather_df is not None and next_ts in future_weather_df.index:\n",
        "            weather_row = future_weather_df.loc[next_ts]\n",
        "        # build feature row\n",
        "        X_row = feature_builder_fn(working_series, weather_row, t_index=next_ts)\n",
        "        # ensure column order matches model\n",
        "        # predict\n",
        "        yhat = model.predict(X_row)[0]\n",
        "        preds.append(yhat)\n",
        "        idx.append(next_ts)\n",
        "        # append predicted value to working_series (so next lags include prediction)\n",
        "        working_series = working_series.append(pd.Series([yhat], index=[next_ts]))\n",
        "        next_ts = next_ts + pd.Timedelta(hours=1)\n",
        "    pred_series = pd.Series(preds, index=idx, name=\"pm25_pred\")\n",
        "    return pred_series\n",
        "\n",
        "def save_model(model, path=\"model.joblib\"):\n",
        "    joblib.dump(model, path)\n",
        "\n",
        "def load_model(path=\"model.joblib\"):\n",
        "    return joblib.load(path)\n"
      ],
      "metadata": {
        "id": "9h4qnE1QIfao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import date, timedelta, datetime\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "# from config import DEFAULT_LAT, DEFAULT_LON, DEFAULT_RADIUS_M, DEFAULT_DAYS_HISTORY\n",
        "# from data_fetch import fetch_openaq_pm25, fetch_open_meteo_weather\n",
        "# from features import build_feature_matrix\n",
        "# from modeling import detect_anomalies, train_regressor, recursive_forecast, save_model, load_model\n",
        "\n",
        "# config.py\n",
        "# Small config defaults — change coordinates to your city\n",
        "\n",
        "DEFAULT_LAT = 13.0827   # Chennai example\n",
        "DEFAULT_LON = 80.2707\n",
        "DEFAULT_RADIUS_M = 10000  # OpenAQ radius in meters\n",
        "DEFAULT_DAYS_HISTORY = 14  # how many days of historical data to pull by default\n",
        "\n",
        "\n",
        "# data_fetch.py\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta, date\n",
        "from dateutil import parser\n",
        "\n",
        "OPENAQ_API = \"https://api.openaq.org/v2/measurements\"\n",
        "OPENMETEO_API = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "def fetch_openaq_pm25(lat, lon, radius_m=10000, days=14, limit_per_page=10000):\n",
        "    \"\"\"\n",
        "    Fetch PM2.5 measurements from OpenAQ (UTC timestamps).\n",
        "    Aggregates to hourly mean.\n",
        "    Returns DataFrame with index = UTC hourly datetime and column 'pm25'.\n",
        "    \"\"\"\n",
        "    date_to = datetime.utcnow().date()\n",
        "    date_from = date_to - timedelta(days=days)\n",
        "    params = {\n",
        "        \"coordinates\": f\"{lat},{lon}\",\n",
        "        \"radius\": radius_m,\n",
        "        \"parameter\": \"pm25\",\n",
        "        \"date_from\": date_from.isoformat(),\n",
        "        \"date_to\": date_to.isoformat(),\n",
        "        \"limit\": limit_per_page,\n",
        "        \"page\": 1,\n",
        "        \"sort\": \"desc\"\n",
        "    }\n",
        "\n",
        "    rows = []\n",
        "    while True:\n",
        "        r = requests.get(OPENAQ_API, params=params, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        j = r.json()\n",
        "        results = j.get(\"results\", [])\n",
        "        if not results:\n",
        "            break\n",
        "        for rec in results:\n",
        "            # date.utc exists like \"2025-10-04T12:00:00+00:00\"\n",
        "            dt = rec.get(\"date\", {}).get(\"utc\")\n",
        "            if not dt:\n",
        "                continue\n",
        "            try:\n",
        "                ts = parser.isoparse(dt)\n",
        "            except Exception:\n",
        "                continue\n",
        "            rows.append({\"timestamp\": ts, \"pm25\": rec.get(\"value\")})\n",
        "        # paging\n",
        "        params[\"page\"] += 1\n",
        "        # avoid infinite loop if server returns huge data; break if less than limit\n",
        "        if len(results) < limit_per_page:\n",
        "            break\n",
        "\n",
        "    if not rows:\n",
        "        return pd.DataFrame(columns=[\"pm25\"]).astype({\"pm25\": \"float64\"})\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
        "    df = df.set_index(\"timestamp\")\n",
        "    # resample to hourly mean\n",
        "    hourly = df.resample(\"H\").mean().sort_index()\n",
        "    return hourly\n",
        "\n",
        "def fetch_open_meteo_weather(lat, lon, start_date: date, end_date: date, timezone=\"UTC\"):\n",
        "    \"\"\"\n",
        "    Pull hourly weather variables from Open-Meteo.\n",
        "    start_date/end_date are date objects (YYYY-MM-DD).\n",
        "    Returns DataFrame indexed by UTC hourly timestamps with columns:\n",
        "      temperature_2m, relativehumidity_2m, windspeed_10m, winddirection_10m, pressure_msl\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        \"latitude\": lat,\n",
        "        \"longitude\": lon,\n",
        "        \"hourly\": \",\".join(\n",
        "            [\"temperature_2m\", \"relativehumidity_2m\", \"windspeed_10m\", \"winddirection_10m\", \"pressure_msl\"]\n",
        "        ),\n",
        "        \"start_date\": start_date.isoformat(),\n",
        "        \"end_date\": end_date.isoformat(),\n",
        "        \"timezone\": timezone  # can pass \"UTC\" or \"auto\"\n",
        "    }\n",
        "    r = requests.get(OPENMETEO_API, params=params, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    j = r.json()\n",
        "    hourly = j.get(\"hourly\", {})\n",
        "    if not hourly:\n",
        "        return pd.DataFrame()\n",
        "    times = [pd.to_datetime(t).tz_convert(None) if pd.to_datetime(t).tzinfo else pd.to_datetime(t) for t in hourly.get(\"time\", [])]\n",
        "    df = pd.DataFrame(hourly)\n",
        "    # drop the time column duplication\n",
        "    df = df.drop(columns=[\"time\"], errors=\"ignore\")\n",
        "    df.index = pd.to_datetime(hourly[\"time\"])\n",
        "    # ensure timezone naive UTC for alignment\n",
        "    df.index = pd.to_datetime(df.index).tz_convert(None)\n",
        "    df = df.sort_index()\n",
        "    return df\n",
        "\n",
        "# features.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def add_time_features(df):\n",
        "    df = df.copy()\n",
        "    # ensure datetime index\n",
        "    idx = pd.DatetimeIndex(df.index)\n",
        "    df[\"hour\"] = idx.hour\n",
        "    df[\"weekday\"] = idx.weekday\n",
        "    df[\"month\"] = idx.month\n",
        "    return df\n",
        "\n",
        "def make_lag_roll_features(df, target_col=\"pm25\", max_lag=24):\n",
        "    \"\"\"\n",
        "    df must have 'pm25' in index-aligned rows. Returns DataFrame with lag & rolling features.\n",
        "    \"\"\"\n",
        "    out = df.copy()\n",
        "    # lags\n",
        "    for lag in range(1, max_lag + 1):\n",
        "        out[f\"lag_{lag}\"] = out[target_col].shift(lag)\n",
        "    # rolling windows\n",
        "    out[\"roll_mean_3\"] = out[target_col].rolling(3, min_periods=1).mean().shift(1)\n",
        "    out[\"roll_mean_6\"] = out[target_col].rolling(6, min_periods=1).mean().shift(1)\n",
        "    out[\"roll_mean_24\"] = out[target_col].rolling(24, min_periods=1).mean().shift(1)\n",
        "    out[\"roll_std_24\"] = out[target_col].rolling(24, min_periods=1).std().shift(1).fillna(0.0)\n",
        "    return out\n",
        "\n",
        "def build_feature_matrix(pm_df, weather_df=None, max_lag=24):\n",
        "    \"\"\"\n",
        "    pm_df: DataFrame with index hourly, column 'pm25'\n",
        "    weather_df: DataFrame with hourly weather variables aligned to pm_df index (can be None)\n",
        "    Returns X (features), y (target)\n",
        "    \"\"\"\n",
        "    df = pm_df.copy()\n",
        "    if weather_df is not None and not weather_df.empty:\n",
        "        # join weather features (align by index)\n",
        "        df = df.join(weather_df, how=\"left\")\n",
        "    # create time features\n",
        "    df = add_time_features(df)\n",
        "    # lags/rolling\n",
        "    df = make_lag_roll_features(df, target_col=\"pm25\", max_lag=max_lag)\n",
        "    # anomaly flag might later be added outside\n",
        "    # drop rows where target is NaN (can't train on missing y)\n",
        "    y = df[\"pm25\"].copy()\n",
        "    X = df.drop(columns=[\"pm25\"])\n",
        "    # fill missing numeric features sensibly\n",
        "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
        "    X[numeric_cols] = X[numeric_cols].fillna(method=\"ffill\").fillna(method=\"bfill\").fillna(0.0)\n",
        "    return X, y\n",
        "\n",
        "# modeling.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest, HistGradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import joblib\n",
        "\n",
        "def detect_anomalies(series, contamination=0.02, random_state=42):\n",
        "    \"\"\"\n",
        "    series: pandas Series of pm25 values (indexed by time)\n",
        "    returns df with 'anomaly' column (True if anomaly)\n",
        "    \"\"\"\n",
        "    clean = series.fillna(-999).values.reshape(-1, 1)\n",
        "    iso = IsolationForest(contamination=contamination, random_state=random_state)\n",
        "    mask = iso.fit_predict(clean)  # -1 anomaly, 1 normal\n",
        "    anomaly = pd.Series(mask == -1, index=series.index, name=\"anomaly\")\n",
        "    return anomaly\n",
        "\n",
        "def train_regressor(X_train, y_train, X_val=None, y_val=None, random_state=42):\n",
        "    \"\"\"\n",
        "    Fits a time-aware gradient booster (HistGradientBoostingRegressor with early stop).\n",
        "    Returns model and optionally validation MAE.\n",
        "    \"\"\"\n",
        "    model = HistGradientBoostingRegressor(max_iter=400, early_stopping=True, random_state=random_state)\n",
        "    model.fit(X_train, y_train)\n",
        "    val_mae = None\n",
        "    if X_val is not None and y_val is not None:\n",
        "        preds = model.predict(X_val)\n",
        "        val_mae = mean_absolute_error(y_val, preds)\n",
        "    return model, val_mae\n",
        "\n",
        "def recursive_forecast(model, last_known_pm, feature_builder_fn, future_weather_df=None,\n",
        "                       horizon=24, max_lag=24):\n",
        "    \"\"\"\n",
        "    model: trained regressor accepting the features created by feature_builder_fn\n",
        "    last_known_pm: pandas Series indexed by time (most recent value last) including available history for lags\n",
        "    feature_builder_fn: function that takes (pm_series, weather_row, t_index) -> DataFrame with a single row of features (matching training X columns)\n",
        "    future_weather_df: DataFrame indexed by future timestamps with weather columns (optional)\n",
        "    Returns pandas Series of predictions indexed by future timestamps\n",
        "    \"\"\"\n",
        "    preds = []\n",
        "    idx = []\n",
        "    working_series = last_known_pm.copy().astype(float)\n",
        "\n",
        "    # start forecast at next hour\n",
        "    next_ts = working_series.index[-1] + pd.Timedelta(hours=1)\n",
        "    for h in range(horizon):\n",
        "        # select weather for this hour if provided\n",
        "        weather_row = None\n",
        "        if future_weather_df is not None and next_ts in future_weather_df.index:\n",
        "            weather_row = future_weather_df.loc[next_ts]\n",
        "        # build feature row\n",
        "        X_row = feature_builder_fn(working_series, weather_row, t_index=next_ts)\n",
        "        # ensure column order matches model\n",
        "        # predict\n",
        "        yhat = model.predict(X_row)[0]\n",
        "        preds.append(yhat)\n",
        "        idx.append(next_ts)\n",
        "        # append predicted value to working_series (so next lags include prediction)\n",
        "        working_series = working_series.append(pd.Series([yhat], index=[next_ts]))\n",
        "        next_ts = next_ts + pd.Timedelta(hours=1)\n",
        "    pred_series = pd.Series(preds, index=idx, name=\"pm25_pred\")\n",
        "    return pred_series\n",
        "\n",
        "def save_model(model, path=\"model.joblib\"):\n",
        "    joblib.dump(model, path)\n",
        "\n",
        "def load_model(path=\"model.joblib\"):\n",
        "    return joblib.load(path)\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"PM2.5 Nowcast & Forecast\", layout=\"wide\")\n",
        "\n",
        "st.title(\"Live PM2.5 Nowcast & Forecast\")\n",
        "\n",
        "# Sidebar config\n",
        "st.sidebar.header(\"Settings\")\n",
        "lat = st.sidebar.number_input(\"Latitude\", value=float(DEFAULT_LAT))\n",
        "lon = st.sidebar.number_input(\"Longitude\", value=float(DEFAULT_LON))\n",
        "radius = st.sidebar.number_input(\"OpenAQ Radius (m)\", value=int(DEFAULT_RADIUS_M))\n",
        "history_days = st.sidebar.slider(\"History days to fetch\", min_value=3, max_value=60, value=int(DEFAULT_DAYS_HISTORY))\n",
        "horizon = st.sidebar.selectbox(\"Forecast horizon (hours)\", [24, 48])\n",
        "contamination = st.sidebar.slider(\"Anomaly contamination (fraction)\", min_value=0.0, max_value=0.1, value=0.02)\n",
        "\n",
        "if st.sidebar.button(\"Fetch & Train Model\"):\n",
        "    with st.spinner(\"Fetching data from APIs...\"):\n",
        "        # fetch PM2.5\n",
        "        pm_df = fetch_openaq_pm25(lat, lon, radius_m=radius, days=history_days)\n",
        "        if pm_df.empty:\n",
        "            st.error(\"No PM2.5 data returned. Try increasing radius or days, or use different coordinates.\")\n",
        "            st.stop()\n",
        "        # get weather for historical range (Open-Meteo). Use local naive datetime index (UTC)\n",
        "        start = pm_df.index.min().date()\n",
        "        end = datetime.utcnow().date()\n",
        "        weather_df = fetch_open_meteo_weather(lat, lon, start_date=start, end_date=end, timezone=\"UTC\")\n",
        "    st.success(\"Data fetched.\")\n",
        "\n",
        "    # Show recent data\n",
        "    st.subheader(\"Recent PM2.5 (hourly)\")\n",
        "    st.write(pm_df.tail(24))\n",
        "\n",
        "    # Anomaly detection\n",
        "    st.subheader(\"Anomaly detection\")\n",
        "    anomalies = detect_anomalies(pm_df[\"pm25\"], contamination=contamination)\n",
        "    pm_df = pm_df.join(anomalies)\n",
        "    st.metric(\"Most recent PM2.5 (µg/m³)\", f\"{pm_df['pm25'].iloc[-1]:.2f}\", delta=None)\n",
        "    st.dataframe(pm_df.tail(24))\n",
        "\n",
        "    # Build features\n",
        "    X, y = build_feature_matrix(pm_df[[\"pm25\"]], weather_df=weather_df, max_lag=24)\n",
        "    # align to remove rows with missing y\n",
        "    mask = ~y.isna()\n",
        "    X = X.loc[mask]\n",
        "    y = y.loc[mask]\n",
        "\n",
        "    # time split: last 20% as validation\n",
        "    split_idx = int(len(X) * 0.8)\n",
        "    X_train, X_val = X.iloc[:split_idx], X.iloc[split_idx:]\n",
        "    y_train, y_val = y.iloc[:split_idx], y.iloc[split_idx:]\n",
        "\n",
        "    st.write(f\"Training rows: {len(X_train)} | Validation rows: {len(X_val)}\")\n",
        "\n",
        "    # Train model\n",
        "    with st.spinner(\"Training model...\"):\n",
        "        model, val_mae = train_regressor(X_train, y_train, X_val=X_val, y_val=y_val)\n",
        "    st.success(f\"Model trained — validation MAE: {val_mae:.3f}\")\n",
        "\n",
        "    # Save model to file for later reuse\n",
        "    save_model(model, \"pm25_model.joblib\")\n",
        "    st.write(\"Model saved to pm25_model.joblib\")\n",
        "\n",
        "    # Prepare future-weather fetch for horizon (get forecast from now..horizon)\n",
        "    now = datetime.utcnow().replace(minute=0, second=0, microsecond=0)\n",
        "    start_forecast = now.date()\n",
        "    end_forecast = (now + pd.Timedelta(hours=horizon)).date()\n",
        "    future_weather = fetch_open_meteo_weather(lat, lon, start_date=start_forecast, end_date=end_forecast, timezone=\"UTC\")\n",
        "\n",
        "    # helper feature builder used by recursive_forecast (must match X columns and preprocessing)\n",
        "    feature_cols = X.columns.tolist()  # order used during training\n",
        "\n",
        "    def feature_builder(pm_series: pd.Series, weather_row, t_index):\n",
        "        \"\"\"\n",
        "        Build a single-row DataFrame matching training features.\n",
        "        pm_series: historical series including predictions appended.\n",
        "        weather_row: a Series of weather data for t_index (or None)\n",
        "        t_index: timestamp for row\n",
        "        \"\"\"\n",
        "        # create a temp df for the timestamp to reuse feature logic\n",
        "        df_temp = pd.DataFrame(index=[t_index])\n",
        "        # time features\n",
        "        df_temp[\"hour\"] = t_index.hour\n",
        "        df_temp[\"weekday\"] = t_index.weekday\n",
        "        df_temp[\"month\"] = t_index.month\n",
        "        # add weather columns expected (if in training)\n",
        "        if weather_row is not None:\n",
        "            for col in weather_row.index:\n",
        "                df_temp[col] = weather_row[col]\n",
        "        else:\n",
        "            # fill with last known weather using fallback zeros\n",
        "            for col in [\"temperature_2m\", \"relativehumidity_2m\", \"windspeed_10m\", \"winddirection_10m\", \"pressure_msl\"]:\n",
        "                if col in feature_cols:\n",
        "                    # try take last available from future_weather or training weather\n",
        "                    df_temp[col] = 0.0\n",
        "        # lags\n",
        "        for lag in range(1, 25):\n",
        "            df_temp[f\"lag_{lag}\"] = pm_series.shift(lag).iloc[-1]\n",
        "        # rolling features computed from pm_series (use upto most recent values)\n",
        "        df_temp[\"roll_mean_3\"] = pm_series.iloc[-3:].mean() if len(pm_series) >= 3 else pm_series.mean()\n",
        "        df_temp[\"roll_mean_6\"] = pm_series.iloc[-6:].mean() if len(pm_series) >= 6 else pm_series.mean()\n",
        "        df_temp[\"roll_mean_24\"] = pm_series.iloc[-24:].mean() if len(pm_series) >= 24 else pm_series.mean()\n",
        "        df_temp[\"roll_std_24\"] = pm_series.iloc[-24:].std() if len(pm_series) >= 2 else 0.0\n",
        "\n",
        "        # align columns to feature_cols (missing -> 0)\n",
        "        for c in feature_cols:\n",
        "            if c not in df_temp.columns:\n",
        "                df_temp[c] = 0.0\n",
        "        df_temp = df_temp[feature_cols]\n",
        "        # fill any NaNs\n",
        "        df_temp = df_temp.fillna(method=\"ffill\").fillna(method=\"bfill\").fillna(0.0)\n",
        "        return df_temp\n",
        "\n",
        "    # do recursive forecast\n",
        "    last_pm_series = pm_df[\"pm25\"].dropna()\n",
        "    pred_series = recursive_forecast(model, last_pm_series, feature_builder, future_weather_df=future_weather, horizon=horizon, max_lag=24)\n",
        "\n",
        "    # Display forecast plot\n",
        "    st.subheader(\"Forecast (next hours)\")\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=last_pm_series.tail(48).index, y=last_pm_series.tail(48).values,\n",
        "                             mode=\"lines+markers\", name=\"Observed PM2.5\"))\n",
        "    fig.add_trace(go.Scatter(x=pred_series.index, y=pred_series.values,\n",
        "                             mode=\"lines+markers\", name=\"Forecast PM2.5\"))\n",
        "    fig.update_layout(xaxis_title=\"Time (UTC)\", yaxis_title=\"PM2.5 (µg/m³)\", height=500)\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "    # show top features\n",
        "    st.subheader(\"Feature importance (approx.)\")\n",
        "    try:\n",
        "        importances = model.feature_importances_\n",
        "        importance_df = pd.DataFrame({\n",
        "            \"feature\": feature_cols,\n",
        "            \"importance\": importances\n",
        "        }).sort_values(\"importance\", ascending=False).head(20)\n",
        "        st.dataframe(importance_df)\n",
        "    except Exception as e:\n",
        "        st.write(\"Feature importance not available for this model type:\", e)\n",
        "\n",
        "    # show anomalies\n",
        "    st.subheader(\"Anomalies flagged (recent)\")\n",
        "    st.dataframe(pm_df[pm_df[\"anomaly\"]].tail(50))\n",
        "\n",
        "    # allow download of forecast CSV\n",
        "    csv = pd.concat([last_pm_series.tail(48), pred_series]).rename(\"pm25\").to_csv()\n",
        "    st.download_button(\"Download observed+forecast CSV\", csv, file_name=\"pm25_observed_forecast.csv\", mime=\"text/csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBLQfUp-I8at",
        "outputId": "2e25b401-df36-4ff2-fc80-6912fb34828b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJrg2Fr8J1SN",
        "outputId": "33a79253-3c68-4c9b-c3c1-ee9485177b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.169.210.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run streamlit_app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "ISOQcRFQK97-",
        "outputId": "83fd4edb-7d2c-4c1b-a697-7e8286d6da77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.169.210.57:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0Kyour url is: https://all-boxes-act.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}